# Clay

## Description: My attempt at building a multi-modal internal assistant using Local LLM LLama 3.2 Vision. The project uses data for a hypothetical consulting company. 
## The company data was generated with ChatGPT. To answer each query the assistant goes through the following workflow.  
## ![Workflow](workflow.png)

## Demo
![demo](demo.gif)

## TODO
- Add a Graph RAG Pipeline
- Allow base model selection.
- Agent/workflow presets including the option for multi-agent workflow.
- Make the workflow less vertical with the ability to combine sources(DB, Python, Web) when needed. 
- Add more function calls like access to the company calendar.
